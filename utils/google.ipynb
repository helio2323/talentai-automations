{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Navegador:\n",
    "    def __init__(self):\n",
    "        # Configurar opções do Chrome\n",
    "        options = Options()\n",
    "        options.add_argument(\"--enable-automation\")\n",
    "        options.add_argument(\"--start-maximized\")\n",
    "        options.add_argument(\"--disable-notifications\")\n",
    "        options.add_argument(\"--disable-popup-blocking\")\n",
    "        options.add_argument(\"--kiosk-printing\")\n",
    "\n",
    "        #add plugin\n",
    "        options.add_extension('./solver.crx')\n",
    "        \n",
    "        self.servico = Service(ChromeDriverManager().install())\n",
    "        \n",
    "        \n",
    "        # Inicializar o WebDriver do Chrome com as opções configuradas\n",
    "        #self.driver = webdriver.Remote(command_executor=\"http://localhost:4444/wd/hub\", options=options)\n",
    "        self.driver = webdriver.Chrome(service=self.servico, options=options)\n",
    "        self.wait = WebDriverWait(self.driver, 15)\n",
    "        self.by = By\n",
    "        self.locator = {\n",
    "            \"XPATH\": By.XPATH,\n",
    "            \"ID\": By.ID,\n",
    "            \"CLASS_NAME\": By.CLASS_NAME,\n",
    "            \"LINK_TEXT\": By.LINK_TEXT,\n",
    "            \"NAME\": By.NAME,\n",
    "            \"PARTIAL_LINK_TEXT\": By.PARTIAL_LINK_TEXT,\n",
    "            \"TAG_NAME\": By.TAG_NAME,\n",
    "            \"CSS_SELECTOR\": By.CSS_SELECTOR\n",
    "        }        \n",
    "\n",
    "    def get_session_id (self):\n",
    "        return self.driver.session_id\n",
    "\n",
    "    def disable_alert(self):\n",
    "        self.driver.switch_to.alert.dismiss()\n",
    "\n",
    "    def element_get_text(self, element, tag):\n",
    "        if element in self.locator:\n",
    "            try:\n",
    "                # Aguardar até que o elemento seja visível e, em seguida, retornar seu texto\n",
    "                element_text = self.wait.until(EC.visibility_of_element_located((self.locator[element], tag)))\n",
    "                return element_text\n",
    "            except TimeoutException:\n",
    "                print(\"Elemento não encontrado\")   \n",
    "                  \n",
    "    def get_elements(self, element, tag):\n",
    "        if element in self.locator:\n",
    "            try:\n",
    "                # Aguardar até que o elemento seja visível e, em seguida, retornar seu texto\n",
    "                elements = self.wait.until(EC.visibility_of_all_elements_located((self.locator[element], tag)))\n",
    "                return elements\n",
    "            except TimeoutException:\n",
    "                print(\"Elemento não encontrado\")\n",
    "\n",
    "    def get(self, url):\n",
    "        # await asyncio.sleep(0)\n",
    "        self.driver.get(url)\n",
    "    def close(self):\n",
    "    #  await asyncio.sleep(0)\n",
    "        self.driver.quit()   \n",
    "\n",
    "    def close_session(self, session_id):\n",
    "        grid_url = \"https://grid.consium.com.br/wd/hub\"\n",
    "        session_url = f\"{grid_url}/session/{session_id}\"\n",
    "        response = requests.delete(session_url)\n",
    "        if response.status_code == 200:\n",
    "            print(\"Sessão fechada com sucesso!\")\n",
    "        else:\n",
    "            print(\"Falha ao fechar a sessão.\")\n",
    "\n",
    "        return response    \n",
    "    # Funcao para digitar no elemento           \n",
    "    def sendkeys(self, element, tag, keys):\n",
    "    #  await asyncio.sleep(0)\n",
    "        if element in self.locator:\n",
    "            try:\n",
    "                self.wait.until(EC.presence_of_element_located((self.locator[element], tag))).send_keys(keys)\n",
    "            except TimeoutException:\n",
    "                print(\"Elemento não encontrado\")\n",
    "                \n",
    "    # Funcao para clicar no elemento                \n",
    "    def click(self, element, tag):\n",
    "    #  await asyncio.sleep(0)\n",
    "        if element in self.locator:\n",
    "            try:\n",
    "                self.wait.until(EC.visibility_of_element_located((self.locator[element], tag))).click()\n",
    "            except TimeoutException:    \n",
    "                print(\"Elemento não encontrado\")\n",
    "\n",
    "\n",
    "    def get_table_element(self, element, tag):\n",
    "        try:\n",
    "            # Obter o conteúdo HTML da tag <tbody>\n",
    "            html_content = self.wait.until(EC.visibility_of_element_located((self.locator[element], tag))).get_attribute('innerHTML')\n",
    "            # Extrair dados da tabela e transforma em dataframe\n",
    "            data = self.table_to_dataframe(html_content)\n",
    "            qtd_linhas = len(data)\n",
    "            return data, qtd_linhas\n",
    "        except TimeoutException:\n",
    "            print(\"Elemento não encontrado\")\n",
    "\n",
    "    def table_to_dataframe(self, html_content):\n",
    "\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Encontra a tabela desejada (selecionando-a pela classe, id ou outras características)\n",
    "        table = soup.find('table')\n",
    "\n",
    "        # Verifica se a tabela foi encontrada\n",
    "        if table:\n",
    "            # Inicializa uma lista para armazenar os dados da tabela\n",
    "            table_data = []\n",
    "            # Itera sobre as linhas da tabela (<tr>)\n",
    "            for row in table.find_all('tr'):\n",
    "                # Inicializa uma lista para armazenar os dados de uma linha\n",
    "                row_data = []\n",
    "                # Itera sobre as células da linha (<td>)\n",
    "                for cell in row.find_all(['td']):\n",
    "                    # Adiciona o texto da célula à lista de dados da linha\n",
    "                    value = cell.text.strip()\n",
    "                    # Verifica se o valor não está vazio\n",
    "                    if value:\n",
    "                        row_data.append(value)\n",
    "                    else:\n",
    "                        row_data.append(None)\n",
    "                    # Verifica se a célula contém uma tag de âncora (hiperlink)\n",
    "                    link = cell.find('a')\n",
    "                    if link:\n",
    "                        # Se houver uma tag de âncora, adiciona o link (href) à lista de dados da linha\n",
    "                        row_data.append(link.get('href'))\n",
    "                    else:\n",
    "                        row_data.append(None)\n",
    "                # Adiciona os dados da linha à lista de dados da tabela\n",
    "                if row_data:\n",
    "                    table_data.append(row_data)\n",
    "\n",
    "            # Imprime os dados da tabela\n",
    "            \n",
    "            df = pd.DataFrame(table_data)\n",
    "            df.to_excel('arquivo.xlsx', index=False)\n",
    "\n",
    "            return df \n",
    "        \n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_page_exists(navegador):\n",
    "    try:\n",
    "        # Aguarda até 10 segundos para o elemento de erro aparecer\n",
    "        error_element = WebDriverWait(navegador.driver, 4).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'h2.artdeco-empty-state__headline')))\n",
    "        \n",
    "        # Verifica se o texto \"Esta página não existe\" está no elemento\n",
    "        if 'Esta página não existe' in error_element.text:\n",
    "            # Se necessário, você pode adicionar um return ou outro comportamento\n",
    "            # para interromper ou redirecionar o fluxo do seu código aqui.\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    except TimeoutException:\n",
    "        # Se o elemento não for encontrado dentro do tempo, segue normalmente\n",
    "        return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_page_is_not_found(navegador):\n",
    "    try:\n",
    "        # Espera até que o elemento com texto 'Página não encontrada' apareça\n",
    "        navegador.wait.until(EC.presence_of_element_located((By.ID, 'i18n_pt_BR')))\n",
    "    except TimeoutException:\n",
    "        # Se o tempo expirar e não encontrar o texto, retorna False\n",
    "        return False\n",
    "    return True  # Se encontrar o texto, retorna True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"query = gerar_query(cargos, habilidades, bancos_dados, ferramentas, localizacoes)\\ngoogle_query = 'https://www.google.com.br/search?q=' + query\\nprint(google_query)\""
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gerar_query(cargos = [], habilidades = [], bancos_dados = [], ferramentas = [], localizacoes = [], empresa=None):\n",
    "    # Criar a parte da query para os cargos\n",
    "    cargos_query = \" OR \".join([f'\"{cargo}\"' for cargo in cargos])\n",
    "    \n",
    "    # Criar a parte da query para as habilidades\n",
    "    habilidades_query = \" OR \".join([f'\"{habilidade}\"' for habilidade in habilidades])\n",
    "    \n",
    "    # Criar a parte da query para os bancos de dados\n",
    "    bancos_dados_query = \" OR \".join([f'\"{banco}\"' for banco in bancos_dados])\n",
    "    \n",
    "    # Criar a parte da query para as ferramentas\n",
    "    ferramentas_query = \" OR \".join([f'\"{ferramenta}\"' for ferramenta in ferramentas])\n",
    "    \n",
    "    # Criar a parte da query para as localizações\n",
    "    localizacoes_query = \" OR \".join([f'\"{localizacao}\"' for localizacao in localizacoes])\n",
    "    \n",
    "    # Adicionar a empresa, se fornecida\n",
    "    empresa_query = f' \"{empresa}\"' if empresa else \"\"\n",
    "    \n",
    "    # Montar a query final\n",
    "    query = (f'site:linkedin.com/in/ ({cargos_query}) ({habilidades_query}) '\n",
    "             f'({bancos_dados_query}) ({ferramentas_query}) ({localizacoes_query}){empresa_query}')\n",
    "        \n",
    "    return query\n",
    "\n",
    "# Exemplo de uso da função\n",
    "cargos = [\"Backend Developer\", \"Backend Engineer\", \"Desenvolvedor Backend\", \"Engenheiro de Software\", \"Software Engineer\"]\n",
    "habilidades = [\"Python\", \"Django\", \"Flask\", \"FastAPI\", \"REST API\", \"GraphQL\", \"Microservices\"]\n",
    "bancos_dados = [\"SQL\", \"NoSQL\", \"PostgreSQL\", \"MySQL\", \"MongoDB\"]\n",
    "ferramentas = [\"Docker\", \"Kubernetes\", \"Git\", \"GitHub\", \"CI/CD\", \"DevOps\"]\n",
    "localizacoes = [\"Brasil\", \"Brazil\", \"Remoto\", \"Remote\"]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"query = gerar_query(cargos, habilidades, bancos_dados, ferramentas, localizacoes)\n",
    "google_query = 'https://www.google.com.br/search?q=' + query\n",
    "print(google_query)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wait_for_captcha(navegador):\n",
    "\n",
    "    try:\n",
    "        # Aguarda até o elemento estar presente\n",
    "        WebDriverWait(navegador.driver, 120).until(EC.presence_of_element_located((By.CLASS_NAME, \"HZVG1b.Tg7LZd\")))\n",
    "\n",
    "        print(\"Elemento encontrado!\")\n",
    "    except TimeoutException:\n",
    "        print(\"Elemento não encontrado dentro do tempo especificado.\")\n",
    "        # Fecha o navegador em caso de erro\n",
    "        navegador.quit()\n",
    "        # Interrompe a execução do código\n",
    "        raise SystemExit(\"Execução encerrada devido a erro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_results(navegador, max_candidates):\n",
    "    # Determina o número de páginas a serem processadas\n",
    "    max_candidates = round(max_candidates / 5)\n",
    "    perfis = []  # Lista para armazenar todos os perfis\n",
    "\n",
    "    for i in range(max_candidates):\n",
    "        # Busca elementos na página atual\n",
    "        google_results = navegador.driver.find_elements(By.XPATH, '//span[@jscontroller=\"msmzHf\"]')\n",
    "        print(f\"Processando candidato {i+1} de {max_candidates}\")\n",
    "\n",
    "        for result in google_results:\n",
    "            try:\n",
    "                # Tentando obter o link\n",
    "                try:\n",
    "                    link = result.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "\n",
    "                    # Normaliza o prefixo para remover qualquer idioma ou região desnecessários\n",
    "                    for prefix in [\"/pt\", \"/en\", \"/es\", \"/fr\", \"/de\"]:  # Adicione outros idiomas, se necessário\n",
    "                        link = link.replace(prefix, \"\")\n",
    "\n",
    "                    # Remove o prefixo \"https://br.\" para uniformizar os links\n",
    "                    link = link.replace(\"https://br.\", \"https://\")\n",
    "\n",
    "                    # Remove qualquer prefixo antes de linkedin.com (cm., ke., etc.)\n",
    "                    link = link.split('linkedin.com', 1)[-1]  # Mantém a parte após 'linkedin.com'\n",
    "                    link = \"https://linkedin.com\" + link  # Adiciona o prefixo padrão 'https://linkedin.com'\n",
    "\n",
    "                except:\n",
    "                    link = \"Link não encontrado\"\n",
    "\n",
    "\n",
    "                # Adicionando os dados à lista de perfis\n",
    "                perfis.append({\n",
    "                    \"link\": link,\n",
    "                    \"nome\": \"\",\n",
    "                    \"skills\": \"\",\n",
    "                    \"sobre\": \"\",\n",
    "                    \"cargo\": \"\",\n",
    "                    \"experiencia\": [],\n",
    "                    \"educacao\": [],\n",
    "                    \"certificacoes\": [],\n",
    "                    \"contato\": {\n",
    "                        \"email\": \"\",\n",
    "                        \"telefone\": \"\",\n",
    "                        \"linkedin\": \"\",\n",
    "                        \"github\": \"\"\n",
    "                    }\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar candidato: {e}\")\n",
    "        \n",
    "        # Avança para a próxima página\n",
    "        navegador.click(\"ID\", \"pnnext\")\n",
    "\n",
    "    return perfis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linkedin_profile(**kwargs):\n",
    "\n",
    "    cookie = {\n",
    "    \"name\": \"li_at\",\n",
    "    \"value\": os.environ[\"LINKEDIN_COOKIE\"],\n",
    "    \"domain\": \".linkedin.com\"\n",
    "}\n",
    "\n",
    "    navegador = Navegador()\n",
    "\n",
    "\n",
    "    navegador.get('https://www.linkedin.com/')\n",
    "    navegador.driver.add_cookie(cookie)\n",
    "\n",
    "    navegador.get('https://www.google.com.br/')\n",
    "\n",
    "    query = gerar_query(cargos = kwargs.get(\"cargos\", []), \n",
    "                habilidades = kwargs.get(\"habilidades\", []), \n",
    "                bancos_dados = kwargs.get(\"bancos_dados\", []), \n",
    "                ferramentas = kwargs.get(\"ferramentas\", []), \n",
    "                localizacoes = kwargs.get(\"localizacoes\", [])\n",
    "                )\n",
    "    print(query)    \n",
    "    navegador.get(f'https://www.google.com.br/search?q={query}')\n",
    "\n",
    "    wait_for_captcha(navegador)\n",
    "\n",
    "    max_interactions = kwargs.get(\"max_interactions\", 5)\n",
    "\n",
    "    google_result = get_google_results(navegador, max_interactions)\n",
    "\n",
    "    navegador.close()\n",
    "    \n",
    "\n",
    "    return google_result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_certifications(navegador, profile_url):\n",
    "    # pega certificacoes\n",
    "\n",
    "    import time\n",
    "    import json\n",
    "\n",
    "    certification_url = profile_url + \"/details/certifications/\"\n",
    "\n",
    "    navegador.get(certification_url)\n",
    "    if not is_page_exists(navegador):\n",
    "        return []\n",
    "    # tratar caso nao tenha certificacoes\n",
    "    try:\n",
    "        navegador.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.t-20.t-bold.ph3.pt3.pb2')))\n",
    "\n",
    "\n",
    "        navegador.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "        html = navegador.driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        certification_sections = soup.select('.pvs-list__paged-list-item')\n",
    "\n",
    "        certifications_data = []\n",
    "\n",
    "        # Iterando pelas seções de certificações\n",
    "        for section in certification_sections:\n",
    "            try:\n",
    "                # Extraindo informações específicas\n",
    "                certification_name = section.select_one('.mr1.hoverable-link-text.t-bold span[aria-hidden=\"true\"]').get_text(strip=True) if section.select_one('.mr1.hoverable-link-text.t-bold span[aria-hidden=\"true\"]') else \"N/A\"\n",
    "                issuer = section.select_one('.t-14.t-normal span[aria-hidden=\"true\"]').get_text(strip=True) if section.select_one('.t-14.t-normal span[aria-hidden=\"true\"]') else \"N/A\"\n",
    "                issue_date = section.select_one('.pvs-entity__caption-wrapper span[aria-hidden=\"true\"]').get_text(strip=True) if section.select_one('.pvs-entity__caption-wrapper span[aria-hidden=\"true\"]') else \"N/A\"\n",
    "                credential_id = section.select_one('.t-14.t-normal.t-black--light span[aria-hidden=\"true\"]').get_text(strip=True) if section.select_one('.t-14.t-normal.t-black--light span[aria-hidden=\"true\"]') else \"N/A\"\n",
    "                school_url = section.select_one('a.optional-action-target-wrapper[href]')['href'] if section.select_one('a.optional-action-target-wrapper[href]') else \"N/A\"\n",
    "                credential_url = section.select_one('a.artdeco-button[href]')['href'] if section.select_one('a.artdeco-button[href]') else \"N/A\"\n",
    "                logo_element = soup.select_one('img[src*=\"company-logo_100_100\"]')\n",
    "                logo_url = logo_element.get('src') if logo_element else \"N/A\"\n",
    "                \n",
    "                # Adicionando ao JSON\n",
    "                certifications_data.append({\n",
    "                    \"certification_name\": certification_name,\n",
    "                    \"issuer\": issuer,\n",
    "                    \"issue_date\": issue_date,\n",
    "                    \"credential_id\": credential_id,\n",
    "                    \"credential_url\": credential_url,\n",
    "                    \"school_url\": school_url,\n",
    "                    \"school_logo_url\": logo_url\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar uma seção: {e}\")\n",
    "\n",
    "        # Salvando como JSON\n",
    "        with open(\"certifications.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(certifications_data, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        return certifications_data\n",
    "\n",
    "    except TimeoutException:\n",
    "        return [{\n",
    "            \"certification_name\": \"N/A\",\n",
    "            \"issuer\": \"N/A\",\n",
    "            \"issue_date\": \"N/A\",\n",
    "            \"credential_id\": \"N/A\",\n",
    "            \"credential_url\": \"N/A\",\n",
    "            \"school_url\": \"N/A\"\n",
    "        }]\n",
    "    print(\"Dados de certificações extraídos e salvos em 'certifications.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_education(navegador, profile_url):\n",
    "    # pega educacao\n",
    "    import time\n",
    "    import json\n",
    "\n",
    "    education_url = profile_url + \"/details/education/\"\n",
    "    #class t-20 t-bold ph3 pt3 pb2\n",
    "    navegador.get(education_url)\n",
    "    if not is_page_exists(navegador):\n",
    "        return []\n",
    "    try:\n",
    "        navegador.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.t-20.t-bold.ph3.pt3.pb2')))\n",
    "\n",
    "        navegador.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "        html = navegador.driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        education_sections = soup.select('.pvs-list__paged-list-item')\n",
    "\n",
    "        education_data = []\n",
    "\n",
    "        for section in education_sections:\n",
    "            try:\n",
    "                # Extraindo informações específicas\n",
    "                institution = section.select_one('.mr1.hoverable-link-text.t-bold span[aria-hidden=\"true\"]').get_text(strip=True) if section.select_one('.mr1.hoverable-link-text.t-bold span[aria-hidden=\"true\"]') else \"N/A\"\n",
    "                degree = section.select_one('.t-14.t-normal span[aria-hidden=\"true\"]').get_text(strip=True) if section.select_one('.t-14.t-normal span[aria-hidden=\"true\"]') else \"N/A\"\n",
    "                dates = section.select_one('.pvs-entity__caption-wrapper span[aria-hidden=\"true\"]').get_text(strip=True) if section.select_one('.pvs-entity__caption-wrapper span[aria-hidden=\"true\"]') else \"N/A\"\n",
    "                logo_element = soup.select_one('img[src*=\"company-logo_100_100\"]')\n",
    "                logo_url = logo_element.get('src') if logo_element else \"N/A\"\n",
    "\n",
    "\n",
    "                # Adicionando ao JSON\n",
    "                education_data.append({\n",
    "                    \"institution\": institution,\n",
    "                    \"degree\": degree,\n",
    "                    \"dates\": dates,\n",
    "                    \"school_logo_url\": logo_url\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar uma seção: {e}\")\n",
    "\n",
    "        # Salvando como JSON\n",
    "        with open(\"education.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(education_data, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "        return education_data\n",
    "    except TimeoutException:\n",
    "        return [{\n",
    "            \"institution\": \"N/A\",\n",
    "            \"degree\": \"N/A\",\n",
    "            \"dates\": \"N/A\"\n",
    "        }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiences(navegador, profile_url):\n",
    "\n",
    "    import json\n",
    "    import time\n",
    "    experience_url = profile_url + \"/details/experience/\"\n",
    "\n",
    "    navegador.get(experience_url)\n",
    "    if not is_page_exists(navegador):\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "    #aguarda a pagina carregar\n",
    "        navegador.wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'pvs-list__paged-list-item')))\n",
    "        #scroll para baixo demorando 2 segundos\n",
    "        navegador.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Extraindo o HTML renderizado\n",
    "        html = navegador.driver.page_source\n",
    "\n",
    "        # Parseando com BeautifulSoup\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Buscando as seções de experiência\n",
    "        experience_sections = soup.select('.pvs-list__paged-list-item')  # Substitua pelo seletor correto\n",
    "\n",
    "        experiences = []\n",
    "\n",
    "        for section in experience_sections:\n",
    "            try:\n",
    "                job_title = section.select_one('.mr1.t-bold').get_text(strip=True) if section.select_one('.mr1.t-bold') else \"N/A\"\n",
    "                company = section.select_one('.t-14.t-normal').get_text(strip=True) if section.select_one('.t-14.t-normal') else \"N/A\"\n",
    "                duration = section.select_one('.pvs-entity__caption-wrapper').get_text(strip=True) if section.select_one('.pvs-entity__caption-wrapper') else \"N/A\"\n",
    "                #classe das competencias display-flex align-items-center t-14 t-normal t-black\n",
    "                description = section.select_one('.display-flex.align-items-center.t-14.t-normal.t-black')  # Substitua com o seletor correto\n",
    "                description_text = description.get_text(strip=True) if description else \"N/A\"\n",
    "\n",
    "                #pega a imagem da empresa\n",
    "                logo_element = soup.select_one('img[src*=\"company-logo_100_100\"]')\n",
    "                logo_url = logo_element.get('src') if logo_element else \"N/A\"\n",
    "\n",
    "                competencies_section = section.select_one('.display-flex.align-items-center.t-14.t-normal.t-black')\n",
    "                \n",
    "                # Adicionando ao JSON\n",
    "                experiences.append({\n",
    "                    \"job_title\": job_title,\n",
    "                    \"company\": company,\n",
    "                    \"duration\": duration,\n",
    "                    \"description\": description_text,\n",
    "                    \"company_logo_url\": logo_url\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar uma seção: {e}\")\n",
    "\n",
    "        # Salvando como JSON\n",
    "        with open(\"experiences.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(experiences, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        return experiences\n",
    "    except TimeoutException:\n",
    "        return [{\n",
    "            \"job_title\": \"N/A\",\n",
    "            \"company\": \"N/A\",\n",
    "            \"duration\": \"N/A\",\n",
    "            \"description\": \"N/A\"\n",
    "        }]\n",
    "# Fechando o navegador.driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_linkedin_profile(linkedin_profile, update_profile=False):\n",
    "\n",
    "    import dotenv\n",
    "    import sqlite3\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    cookie = {\n",
    "        \"name\": \"li_at\",\n",
    "        \"value\": os.environ[\"LINKEDIN_VISITOR_ID\"],\n",
    "        \"domain\": \".linkedin.com\"\n",
    "    }\n",
    "\n",
    "    navegador = Navegador()\n",
    "\n",
    "    navegador.get('https://www.linkedin.com/feed/')\n",
    "\n",
    "    navegador.driver.add_cookie(cookie) \n",
    "\n",
    "    linkedin_prof = linkedin_profile\n",
    "\n",
    "    for profile in linkedin_prof:\n",
    "\n",
    "        #verifica se o perfil ja existe no banco de dados\n",
    "        conn = sqlite3.connect(\"profiles.db\")\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT link FROM profile WHERE link = ?\", (profile['link'],))\n",
    "        if cursor.fetchone() is not None and update_profile == False:\n",
    "            continue\n",
    "\n",
    "        if profile['link'] == \"Link não encontrado\":\n",
    "            continue\n",
    "        print(f\"Coletando dados do perfil numero {linkedin_prof.index(profile)} do total de {len(linkedin_prof)}\")\n",
    "        profile_url = profile['link']\n",
    "\n",
    "        #carregar o perfil\n",
    "        navegador.get(profile_url)\n",
    "        \n",
    "        if not is_page_exists(navegador):\n",
    "            #pula o perfil\n",
    "            continue\n",
    "\n",
    "        if is_page_is_not_found(navegador):\n",
    "            #pula o perfil\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(navegador.driver.page_source, 'html.parser')\n",
    "        #scrola a pagina e aguarda a pagina carregar\n",
    "        navegador.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        try:\n",
    "            # Aumentando o tempo de espera para 20 segundos\n",
    "            name_element = WebDriverWait(navegador.driver, 20).until(\n",
    "                EC.visibility_of_element_located((By.CSS_SELECTOR, 'h1.inline.t-24.v-align-middle.break-words'))\n",
    "            )\n",
    "            name = name_element.text.strip() if name_element else \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Nome não encontrado. Pode ser uma página de erro.\")\n",
    "            name = \"N/A\"\n",
    "\n",
    "        # Verifique se name_element é um objeto BeautifulSoup e use get_text apenas se não for None\n",
    "        \n",
    "\n",
    "        try:\n",
    "\n",
    "            photo_element = soup.select_one('img.pv-top-card-profile-picture__image--show.evi-image')\n",
    "            photo_url = photo_element.get('src') if photo_element else \"N/A\"\n",
    "\n",
    "            headline = soup.find('div', {'class': 'text-body-medium break-words'})\n",
    "            headline = headline.get_text().strip()\n",
    "\n",
    "            about = soup.find('div', {'class': 'display-flex ph5 pv3'}) if soup.find('div', {'class': 'display-flex ph5 pv3'}) else \"N/A\"\n",
    "        except TimeoutException:\n",
    "            headline = \"N/A\"\n",
    "            about = \"N/A\"\n",
    "            photo_url = \"N/A\"\n",
    "        if about == \"N/A\":\n",
    "            about = \"N/A\"\n",
    "        else:\n",
    "            about = about.get_text().strip()\n",
    "\n",
    "        #atualiza o perfil\n",
    "        profile['nome'] = name\n",
    "        profile['skills'] = headline\n",
    "        profile['sobre'] = about\n",
    "        profile['foto'] = photo_url\n",
    "        #coleta de experiencia\n",
    "        print('-'*100)\n",
    "        print(f\"coletando experiencia, educacao e certificacoes de {name}\")\n",
    "        experiences = get_experiences(navegador, profile_url)\n",
    "        profile['experiencia'] = experiences\n",
    "        #coleta de educacao\n",
    "        education = get_education(navegador, profile_url)\n",
    "        profile['educacao'] = education\n",
    "        #coleta de certificacoes\n",
    "        certifications = get_certifications(navegador, profile_url)\n",
    "        profile['certificacoes'] = certifications\n",
    "        \n",
    "        print(f\"dados de {name} coletados com sucesso\")\n",
    "        print('-'*100)\n",
    "\n",
    "    navegador.close()\n",
    "    \n",
    "    return linkedin_prof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela criada com sucesso!\n",
      "Dados inseridos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "\n",
    "# Conexão com o banco de dados (ou criação do arquivo se não existir)\n",
    "conn = sqlite3.connect(\"profiles.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Criação da tabela\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS profile (\n",
    "    link TEXT,\n",
    "    nome TEXT,\n",
    "    skills TEXT,\n",
    "    sobre TEXT,\n",
    "    cargo TEXT,\n",
    "    experiencia TEXT,\n",
    "    educacao TEXT,\n",
    "    certificacoes TEXT,\n",
    "    contato_email TEXT,\n",
    "    contato_telefone TEXT,\n",
    "    contato_linkedin TEXT,\n",
    "    contato_github TEXT,\n",
    "    foto TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "print(\"Tabela criada com sucesso!\")\n",
    "\n",
    "# Dados do JSON fornecido\n",
    "data = {\n",
    "    \"link\": \"https://linkedin.com/in/joaopedroliveira/en\",\n",
    "    \"nome\": \"Joao Pedro Oliveira\",\n",
    "    \"skills\": \"Data Engineer | CI/CD | Python | Docker | Terraform | AWS Certified\",\n",
    "    \"sobre\": \"Data Engineer with extensive experience in consulting and product companies, specializing in developing and managing complex data infrastructures, ETLs, and public cloud implementations (AWS).Technical Skills: - Proficient in Python, R, SQL, DBT, and tools like Docker and Terraform. - Expertise in developing ETL pipelines for both streaming and batch data. - Extensive experience in building interactive dashboards for stakeholder presentations using tools like Metabase. - Contributor to open-source software as a developer with the Elixir programming language.Experienced with Linux systems and certified as an AWS Cloud Practitioner with two years of experience managing data infrastructure in a regulated financial company. Certification:  AWS Cloud Practitioner (09/2021).Open Source Contributions: Contributor to the Explorer library (gh: elixir-nx/explorer), which adds DataFrames functionality to Elixir.Language Proficiency: Native/Fluent Portuguese Advanced English Basic FrenchAcademic Background: Graduate Research Assistant in the Political Science Department at Emory University (USA). Research Assistant at the Getúlio Vargas Foundation (FGV/EPGE). Data Intern in the Economics Department at PUC-Rio. Research Assistant at the Institute for Applied Economic Research (IPEA). Bachelor's degree in International Relations from PUC-Rio.\",\n",
    "    \"cargo\": \"\",\n",
    "    \"experiencia\": [],\n",
    "    \"educacao\": [],\n",
    "    \"certificacoes\": [],\n",
    "    \"contato\": {\n",
    "        \"email\": \"\",\n",
    "        \"telefone\": \"\",\n",
    "        \"linkedin\": \"\",\n",
    "        \"github\": \"\"\n",
    "    },\n",
    "    \"foto\": \"https://media.licdn.com/dms/image/v2/C4E03AQH3t65XHMHQ4g/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1642634082175?e=1743033600&v=beta&t=Om6aH4hQNx5b57xzDdEoTJbfQsesuMtUmunfYARS3xE\"\n",
    "}\n",
    "\n",
    "# Inserção de dados\n",
    "cursor.execute('''\n",
    "INSERT INTO profile (\n",
    "    link, nome, skills, sobre, cargo, experiencia, educacao, certificacoes,\n",
    "    contato_email, contato_telefone, contato_linkedin, contato_github, foto\n",
    ") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "''', (\n",
    "    data[\"link\"],\n",
    "    data[\"nome\"],\n",
    "    data[\"skills\"],\n",
    "    data[\"sobre\"],\n",
    "    data[\"cargo\"],\n",
    "    json.dumps(data[\"experiencia\"]),  # Serializando lista como JSON\n",
    "    json.dumps(data[\"educacao\"]),  # Serializando lista como JSON\n",
    "    json.dumps(data[\"certificacoes\"]),  # Serializando lista como JSON\n",
    "    data[\"contato\"][\"email\"],\n",
    "    data[\"contato\"][\"telefone\"],\n",
    "    data[\"contato\"][\"linkedin\"],\n",
    "    data[\"contato\"][\"github\"],\n",
    "    data[\"foto\"]\n",
    "))\n",
    "\n",
    "# Confirmação e encerramento\n",
    "conn.commit()\n",
    "print(\"Dados inseridos com sucesso!\")\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "\n",
    "def salvar_ou_atualizar_perfis_em_banco(dados, nome_arquivo_db=\"profiles.db\"):\n",
    "    \"\"\"\n",
    "    Salva ou atualiza uma lista de perfis no banco de dados SQLite.\n",
    "\n",
    "    :param dados: Lista de dicionários representando os perfis.\n",
    "    :param nome_arquivo_db: Nome do arquivo do banco de dados SQLite.\n",
    "    \"\"\"\n",
    "    # Conexão com o banco de dados\n",
    "    conn = sqlite3.connect(nome_arquivo_db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Certificar-se de que a tabela existe\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS profile (\n",
    "        link TEXT PRIMARY KEY,\n",
    "        nome TEXT,\n",
    "        skills TEXT,\n",
    "        sobre TEXT,\n",
    "        cargo TEXT,\n",
    "        experiencia TEXT,\n",
    "        educacao TEXT,\n",
    "        certificacoes TEXT,\n",
    "        contato_email TEXT,\n",
    "        contato_telefone TEXT,\n",
    "        contato_linkedin TEXT,\n",
    "        contato_github TEXT,\n",
    "        foto TEXT\n",
    "    );\n",
    "    ''')\n",
    "\n",
    "    for perfil in dados:\n",
    "        link = perfil.get(\"link\", \"\")\n",
    "        \n",
    "        # Verificar se o link já existe na tabela\n",
    "        cursor.execute(\"SELECT link FROM profile WHERE link = ?\", (link,))\n",
    "        if cursor.fetchone() is not None:\n",
    "            # Atualizar o registro existente\n",
    "            cursor.execute('''\n",
    "            UPDATE profile\n",
    "            SET nome = ?, skills = ?, sobre = ?, cargo = ?, experiencia = ?, \n",
    "                educacao = ?, certificacoes = ?, contato_email = ?, contato_telefone = ?, \n",
    "                contato_linkedin = ?, contato_github = ?, foto = ?\n",
    "            WHERE link = ?\n",
    "            ''', (\n",
    "                perfil.get(\"nome\", \"\"),\n",
    "                perfil.get(\"skills\", \"\"),\n",
    "                perfil.get(\"sobre\", \"\"),\n",
    "                perfil.get(\"cargo\", \"\"),\n",
    "                json.dumps(perfil.get(\"experiencia\", [])),  # Serializar lista como JSON\n",
    "                json.dumps(perfil.get(\"educacao\", [])),  # Serializar lista como JSON\n",
    "                json.dumps(perfil.get(\"certificacoes\", [])),  # Serializar lista como JSON\n",
    "                perfil.get(\"contato\", {}).get(\"email\", \"\"),\n",
    "                perfil.get(\"contato\", {}).get(\"telefone\", \"\"),\n",
    "                perfil.get(\"contato\", {}).get(\"linkedin\", \"\"),\n",
    "                perfil.get(\"contato\", {}).get(\"github\", \"\"),\n",
    "                perfil.get(\"foto\", \"\"),\n",
    "                link\n",
    "            ))\n",
    "            print(f\"Registro com o link '{link}' atualizado com sucesso.\")\n",
    "        else:\n",
    "            # Inserir um novo registro\n",
    "            cursor.execute('''\n",
    "            INSERT INTO profile (\n",
    "                link, nome, skills, sobre, cargo, experiencia, educacao, certificacoes,\n",
    "                contato_email, contato_telefone, contato_linkedin, contato_github, foto\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            ''', (\n",
    "                link,\n",
    "                perfil.get(\"nome\", \"\"),\n",
    "                perfil.get(\"skills\", \"\"),\n",
    "                perfil.get(\"sobre\", \"\"),\n",
    "                perfil.get(\"cargo\", \"\"),\n",
    "                json.dumps(perfil.get(\"experiencia\", [])),  # Serializar lista como JSON\n",
    "                json.dumps(perfil.get(\"educacao\", [])),  # Serializar lista como JSON\n",
    "                json.dumps(perfil.get(\"certificacoes\", [])),  # Serializar lista como JSON\n",
    "                perfil.get(\"contato\", {}).get(\"email\", \"\"),\n",
    "                perfil.get(\"contato\", {}).get(\"telefone\", \"\"),\n",
    "                perfil.get(\"contato\", {}).get(\"linkedin\", \"\"),\n",
    "                perfil.get(\"contato\", {}).get(\"github\", \"\"),\n",
    "                perfil.get(\"foto\", \"\")\n",
    "            ))\n",
    "            print(f\"Registro com o link '{link}' salvo com sucesso.\")\n",
    "\n",
    "    # Confirmar transações e fechar conexão\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"Processamento concluído. Banco de dados atualizado: {nome_arquivo_db}!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Colocar no update profile para que salve o usuario no BUBBLE sempre que atualizar o dado\n",
    "- Lembrar que deve ser passado o job_bubble_id para que salve o usuario no BUBBLE\n",
    "- Avaliar como esse dado vai entrar no BUBBLE se vai utilizar o BD existente ou criar uma nova estrutura de tabelas para receber os dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_profiles(cargos, habilidades, ferramentas, localizacoes, max_interactions, job_bubble_id):\n",
    "\n",
    "    linkedin_profile = []\n",
    "    update_profile = True\n",
    "\n",
    "    linkedin_profile = get_linkedin_profile(\n",
    "        cargos=[\"Devops\"],\n",
    "        habilidades=[\"Natural Language Processing\", \"NLP\", \"Python\", \"Machine Learning\", \"AI\", \"TensorFlow\", \"PyTorch\", \"Deep Learning\", \"Data Analysis\"],\n",
    "        ferramentas=[\"Git\", \"Docker\", \"AWS\", \"Google Cloud\"],\n",
    "        localizacoes=[\"Brasil\"],\n",
    "        max_interactions=5\n",
    "    )\n",
    "\n",
    "    #corta para que busque somente 5 perfis\n",
    "    linkedin_profile = linkedin_profile[:5]\n",
    "\n",
    "    total_profiles = update_linkedin_profile(linkedin_profile, update_profile)\n",
    "\n",
    "    salvar_ou_atualizar_perfis_em_banco(total_profiles)       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salva o json\n",
    "with open(\"linkedin_profile.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(total_profiles, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela 'profile' limpa com sucesso.\n",
      "Banco de dados 'profiles.db' foi completamente limpo.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def limpar_banco_de_dados(nome_arquivo_db=\"profiles.db\"):\n",
    "    \"\"\"\n",
    "    Remove todos os registros de todas as tabelas no banco de dados SQLite.\n",
    "\n",
    "    :param nome_arquivo_db: Nome do arquivo do banco de dados SQLite.\n",
    "    \"\"\"\n",
    "    # Conexão com o banco de dados\n",
    "    conn = sqlite3.connect(nome_arquivo_db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Obter todas as tabelas do banco de dados\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tabelas = cursor.fetchall()\n",
    "\n",
    "    if not tabelas:\n",
    "        print(\"Nenhuma tabela encontrada no banco de dados.\")\n",
    "    else:\n",
    "        for tabela in tabelas:\n",
    "            nome_tabela = tabela[0]\n",
    "            # Limpar a tabela\n",
    "            cursor.execute(f\"DELETE FROM {nome_tabela};\")\n",
    "            print(f\"Tabela '{nome_tabela}' limpa com sucesso.\")\n",
    "\n",
    "        # Confirmar alterações\n",
    "        conn.commit()\n",
    "\n",
    "    # Fechar a conexão\n",
    "    conn.close()\n",
    "    print(f\"Banco de dados '{nome_arquivo_db}' foi completamente limpo.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
